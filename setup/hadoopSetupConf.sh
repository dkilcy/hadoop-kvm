#!/bin/bash
#
##############################################################################
# This software is provided AS-IS with no copyright, warranty or support.
# Since it has no copyright, if you can make money with it, good for you.
# If you mess up your system with this then that's on you.
# Email bug reports, suggested improvements or other comments to:
#       david@kilcyconsulting.com
# All email sent to the above address becomes the property of David Kilcy.
# If you do not agree to these terms then do not use this software.
# You are free to use, modify or distribute this software as long as this 
# header remains in place without modification and you agree to it's terms.
##############################################################################
# @author dkilcy
#
# Hadoop configuration file setup script
#
# Tested on CentOS 6.4
#

DIR="/tmp"

echo "Remove exit call when ready to turn up"
#exit

if [ $USER != "root" ]; then echo "Must be run as root, aborting."; exit -1; fi 

##############################################################################

preConf() {
BAK_EXT=`date +%s`
echo "Backing up $1 to $1.$BAK_EXT"
cp $1 $1.$BAK_EXT

echo "Generating $1 ..."
echo "<?xml version="1.0"?>" > $1
echo "<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>" >> $1
echo "" >> $1
echo "<!-- Generated from $0 on `date` -->" >> $1
echo "" >> $1
echo "<configuration>" >> $1
}

appendConf() {
echo "	<property>" >> $1
echo "          <name>$2</name>" >> $1
echo "          <value>$3</value>" >> $1
echo "          <description>$4</description>" >> $1
echo "	</property>" >> $1
}

appendConfFinal() {
echo "  <property>" >> $1
echo "          <name>$2</name>" >> $1
echo "          <value>$3</value>" >> $1
echo "          <final>$4</final>" >> $1
echo "          <description>$5</description>" >> $1
echo "  </property>" >> $1
}

postConf() {
echo "</configuration>" >> $1
}

##############################################################################

echo "Start of program"

##############################################################################

FILE=core-site.xml
preConf $DIR/$FILE
appendConf $DIR/$FILE "fs.default.name" "hdfs://localhost:9000" "URI of NameNode"
postConf $DIR/$FILE

FILE=hdfs-site.xml
preConf $DIR/$FILE
appendConf 	$DIR/$FILE "dfs.name.dir" "/data/hdfs/name" "Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently. If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy."
appendConf 	$DIR/$FILE "dfs.data.dir" "/data/hdfs/data" "Comma separated list of paths on the local filesystem of a DataNode where it should store its blocks. If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices."
appendConfFinal $DIR/$FILE "fs.checkpoint.dir" "/data/hdfs/namesecondary" "true" ""
appendConf 	$DIR/$FILE "dfs.replication" "3" "Default block replication is 3" 
postConf 	$DIR/$FILE

FILE=mapred-site.xml
preConf $DIR/$FILE
appendConf 	$DIR/$FILE "mapred.job.tracker" "localhost:9001" "Host or IP and port of JobTracker"
appendConf 	$DIR/$FILE "mapred.local.dir" "/data/hadoop/mapred/local" ""
appendConf 	$DIR/$FILE "mapred.system.dir" "/data/hadoop/mapred/system" ""
appendConf 	$DIR/$FILE "mapred.tasktracker.map.tasks.maximum" "1" ""
appendConf 	$DIR/$FILE "mapred.tasktracker.reduce.tasks.maximum" "1" ""
appendConf 	$DIR/$FILE "mapred.child.java.opts" "-Xmx256m" ""
postConf $DIR/$FILE

##############################################################################

FILE=hadoop-env.sh

BAK_EXT=`date +%s`
echo "Backing up $DIR/$FILE to $DIR/$FILE.$BAK_EXT"
cp $DIR/$FILE $DIR/$FILE.$BAK_EXT

echo "###############################################################################" >> $DIR/$FILE
echo "# Set Hadoop-specific environment variables here." >> $DIR/FILE
echo "# File generated by $0 at `date`" >> $DIR/$FILE
echo "###############################################################################" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "# The java implementation to use.  Required." >> $DIR/$FILE
echo "export JAVA_HOME=$JAVA_HOME" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "# Extra Java CLASSPATH elements.  Optional." >> $DIR/$FILE
echo "export HADOOP_CLASSPATH=" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "# The maximum amount of heap to use, in MB. Default is 1000." >> $DIR/$FILE
echo "export HADOOP_HEAPSIZE=1000" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "# Extra Java runtime options.  Empty by default." >> $DIR/$FILE
echo "export HADOOP_OPTS=-server" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "# Command specific options appended to HADOOP_OPTS when specified" >> $DIR/$FILE
echo "export HADOOP_NAMENODE_OPTS=\"-Dcom.sun.management.jmxremote \$HADOOP_NAMENODE_OPTS\"" >> $DIR/$FILE
echo "export HADOOP_SECONDARYNAMENODE_OPTS=\"-Dcom.sun.management.jmxremote \$HADOOP_SECONDARYNAMENODE_OPTS\"" >> $DIR/$FILE
echo "export HADOOP_DATANODE_OPTS=\"-Dcom.sun.management.jmxremote \$HADOOP_DATANODE_OPTS\"" >> $DIR/$FILE
echo "export HADOOP_BALANCER_OPTS=\"-Dcom.sun.management.jmxremote \$HADOOP_BALANCER_OPTS\"" >> $DIR/$FILE
echo "export HADOOP_JOBTRACKER_OPTS=\"-Dcom.sun.management.jmxremote \$HADOOP_JOBTRACKER_OPTS\"" >> $DIR/$FILE
echo "" >> $DIR/$FILE
##echo "# Extra ssh options.  Empty by default." >> $DIR/$FILE
##echo "export HADOOP_SSH_OPTS=\"-o ConnectTimeout=1 -o SendEnv=HADOOP_CONF_DIR\"" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "# Where log files are stored.  \$HADOOP_HOME/logs by default." >> $DIR/$FILE
echo "export HADOOP_LOG_DIR=/var/log/hadoop" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "# The directory where pid files are stored. /tmp by default." >> $DIR/$FILE
echo "# NOTE: this should be set to a directory that can only be written to by" >> $DIR/$FILE
echo "# the users that are going to run the hadoop daemons.  Otherwise there is" >> $DIR/$FILE
echo "# the potential for a symlink attack." >> $DIR/$FILE
echo "export HADOOP_PID_DIR=/var/opt/hadoop/pids" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "" >> $DIR/$FILE
echo "" >> $DIR/$FILE

##############################################################################



##############################################################################
##cat /proc/sys/net/ipv6/conf/all/disable_ipv6

##############################################################################

# hadoop namenode -format
# start-all.sh
# stop-all.sh

echo "End of program"
#
# References:
#
